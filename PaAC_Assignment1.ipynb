{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G5t6UtfGQE3"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "fcZ80vSkGaSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test)=cifar10.load_data()"
      ],
      "metadata": {
        "id": "1VGZ0hGJGmI4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcjD3_ZYHXi5",
        "outputId": "2f52bc1b-358b-491b-ea0e-faeac36af607"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n",
            "(10000, 32, 32, 3)\n",
            "(10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=to_categorical(y_train)\n",
        "y_test=to_categorical(y_test)"
      ],
      "metadata": {
        "id": "wXQ893SHHfdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train/255.0\n",
        "X_test=X_test/255.0"
      ],
      "metadata": {
        "id": "-MV3ZjqdIkQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "# kernel_initializer --> set random weights in the neural layer uniformly\n",
        "# pading --> same input/output height/weight dimensions\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1GSWYbwIs9g",
        "outputId": "4b3ceecb-dc51-41bc-fdf0-0a1bec978316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 16, 16, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_8 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_9 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_12 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_10 (Ba  (None, 8, 8, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_11 (Ba  (None, 8, 8, 64)          256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPoolin  (None, 4, 4, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 4, 4, 64)          0         \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 4, 4, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 4, 4, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 4, 4, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 2, 2, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 2, 2, 128)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 439370 (1.68 MB)\n",
            "Trainable params: 438218 (1.67 MB)\n",
            "Non-trainable params: 1152 (4.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=SGD(learning_rate=0.001, momentum=0.95)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# verbose determines how you want to see the status of training\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkZ_AEZXKR01",
        "outputId": "c522c93b-c9d1-49cb-b99e-3d4de2f16c5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "782/782 [==============================] - 17s 17ms/step - loss: 1.7815 - accuracy: 0.3506 - val_loss: 1.4951 - val_accuracy: 0.4477\n",
            "Epoch 2/50\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 1.4211 - accuracy: 0.4805 - val_loss: 1.2601 - val_accuracy: 0.5367\n",
            "Epoch 3/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.2436 - accuracy: 0.5494 - val_loss: 1.1528 - val_accuracy: 0.5776\n",
            "Epoch 4/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 1.0968 - accuracy: 0.6062 - val_loss: 0.9858 - val_accuracy: 0.6457\n",
            "Epoch 5/50\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 1.0096 - accuracy: 0.6372 - val_loss: 1.0341 - val_accuracy: 0.6352\n",
            "Epoch 6/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.9383 - accuracy: 0.6638 - val_loss: 0.8784 - val_accuracy: 0.6916\n",
            "Epoch 7/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.8784 - accuracy: 0.6857 - val_loss: 0.8762 - val_accuracy: 0.6870\n",
            "Epoch 8/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.8270 - accuracy: 0.7042 - val_loss: 0.8237 - val_accuracy: 0.7118\n",
            "Epoch 9/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.7879 - accuracy: 0.7188 - val_loss: 0.8115 - val_accuracy: 0.7108\n",
            "Epoch 10/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.7494 - accuracy: 0.7355 - val_loss: 0.7311 - val_accuracy: 0.7396\n",
            "Epoch 11/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.7161 - accuracy: 0.7460 - val_loss: 0.7006 - val_accuracy: 0.7566\n",
            "Epoch 12/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.6874 - accuracy: 0.7556 - val_loss: 0.6761 - val_accuracy: 0.7636\n",
            "Epoch 13/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.6616 - accuracy: 0.7655 - val_loss: 0.6626 - val_accuracy: 0.7680\n",
            "Epoch 14/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.6382 - accuracy: 0.7725 - val_loss: 0.6541 - val_accuracy: 0.7720\n",
            "Epoch 15/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.6154 - accuracy: 0.7820 - val_loss: 0.6439 - val_accuracy: 0.7797\n",
            "Epoch 16/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.5972 - accuracy: 0.7898 - val_loss: 0.6320 - val_accuracy: 0.7805\n",
            "Epoch 17/50\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.5751 - accuracy: 0.7964 - val_loss: 0.6088 - val_accuracy: 0.7918\n",
            "Epoch 18/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5574 - accuracy: 0.8020 - val_loss: 0.6109 - val_accuracy: 0.7901\n",
            "Epoch 19/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5391 - accuracy: 0.8087 - val_loss: 0.6096 - val_accuracy: 0.7923\n",
            "Epoch 20/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5282 - accuracy: 0.8133 - val_loss: 0.5837 - val_accuracy: 0.8034\n",
            "Epoch 21/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.5102 - accuracy: 0.8188 - val_loss: 0.6031 - val_accuracy: 0.7948\n",
            "Epoch 22/50\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.4931 - accuracy: 0.8258 - val_loss: 0.5777 - val_accuracy: 0.8069\n",
            "Epoch 23/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4839 - accuracy: 0.8264 - val_loss: 0.5645 - val_accuracy: 0.8091\n",
            "Epoch 24/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4663 - accuracy: 0.8349 - val_loss: 0.5484 - val_accuracy: 0.8151\n",
            "Epoch 25/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4560 - accuracy: 0.8382 - val_loss: 0.6072 - val_accuracy: 0.7948\n",
            "Epoch 26/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4411 - accuracy: 0.8435 - val_loss: 0.5532 - val_accuracy: 0.8149\n",
            "Epoch 27/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4322 - accuracy: 0.8468 - val_loss: 0.5590 - val_accuracy: 0.8096\n",
            "Epoch 28/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4190 - accuracy: 0.8524 - val_loss: 0.5518 - val_accuracy: 0.8150\n",
            "Epoch 29/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.4119 - accuracy: 0.8534 - val_loss: 0.5476 - val_accuracy: 0.8181\n",
            "Epoch 30/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.4035 - accuracy: 0.8563 - val_loss: 0.5539 - val_accuracy: 0.8162\n",
            "Epoch 31/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3905 - accuracy: 0.8620 - val_loss: 0.6257 - val_accuracy: 0.7960\n",
            "Epoch 32/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3822 - accuracy: 0.8643 - val_loss: 0.5324 - val_accuracy: 0.8234\n",
            "Epoch 33/50\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.3685 - accuracy: 0.8692 - val_loss: 0.5562 - val_accuracy: 0.8220\n",
            "Epoch 34/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.3614 - accuracy: 0.8712 - val_loss: 0.5435 - val_accuracy: 0.8226\n",
            "Epoch 35/50\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.3566 - accuracy: 0.8735 - val_loss: 0.5504 - val_accuracy: 0.8219\n",
            "Epoch 36/50\n",
            "782/782 [==============================] - 12s 16ms/step - loss: 0.3431 - accuracy: 0.8773 - val_loss: 0.5297 - val_accuracy: 0.8317\n",
            "Epoch 37/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3381 - accuracy: 0.8764 - val_loss: 0.5237 - val_accuracy: 0.8290\n",
            "Epoch 38/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3286 - accuracy: 0.8841 - val_loss: 0.5201 - val_accuracy: 0.8306\n",
            "Epoch 39/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3218 - accuracy: 0.8860 - val_loss: 0.5261 - val_accuracy: 0.8313\n",
            "Epoch 40/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3148 - accuracy: 0.8876 - val_loss: 0.5403 - val_accuracy: 0.8279\n",
            "Epoch 41/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.3056 - accuracy: 0.8909 - val_loss: 0.5418 - val_accuracy: 0.8270\n",
            "Epoch 42/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.2987 - accuracy: 0.8919 - val_loss: 0.6014 - val_accuracy: 0.8177\n",
            "Epoch 43/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.2891 - accuracy: 0.8962 - val_loss: 0.5454 - val_accuracy: 0.8300\n",
            "Epoch 44/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.2883 - accuracy: 0.8964 - val_loss: 0.5341 - val_accuracy: 0.8256\n",
            "Epoch 45/50\n",
            "782/782 [==============================] - 13s 17ms/step - loss: 0.2812 - accuracy: 0.9008 - val_loss: 0.5425 - val_accuracy: 0.8331\n",
            "Epoch 46/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.2744 - accuracy: 0.9022 - val_loss: 0.5439 - val_accuracy: 0.8339\n",
            "Epoch 47/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.2698 - accuracy: 0.9043 - val_loss: 0.5517 - val_accuracy: 0.8301\n",
            "Epoch 48/50\n",
            "782/782 [==============================] - 15s 19ms/step - loss: 0.2612 - accuracy: 0.9073 - val_loss: 0.5951 - val_accuracy: 0.8217\n",
            "Epoch 49/50\n",
            "782/782 [==============================] - 14s 18ms/step - loss: 0.2540 - accuracy: 0.9090 - val_loss: 0.5611 - val_accuracy: 0.8345\n",
            "Epoch 50/50\n",
            "782/782 [==============================] - 13s 16ms/step - loss: 0.2494 - accuracy: 0.9111 - val_loss: 0.5469 - val_accuracy: 0.8343\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x782451b03850>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result=model.evaluate(X_test, y_test, verbose=1)\n",
        "print(result[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2RjVTfvXWuft",
        "outputId": "b1b972a2-8370-4c89-f309-8b664f9a5350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 4ms/step - loss: 0.5469 - accuracy: 0.8343\n",
            "0.8342999815940857\n"
          ]
        }
      ]
    }
  ]
}
